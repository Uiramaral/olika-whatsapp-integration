// utils/ai_processor.js

const { downloadContentFromMessage, getContentType } = require('@whiskeysockets/baileys');
const { OpenAI } = require('openai');
const pdf = require('pdf-parse');
const fs = require('fs');
const path = require('path');
const logger = require('../config/logger'); 

// Configura√ß√£o da OpenAI (necess√°ria aqui para as chamadas condicionais Whisper)
const OPENAI_TIMEOUT = parseInt(process.env.OPENAI_TIMEOUT) * 1000 || 30000; 
const openai = new OpenAI({ 
    apiKey: process.env.OPENAI_API_KEY,
    timeout: OPENAI_TIMEOUT
});

const TEMP_DIR = path.resolve(__dirname, '..', '..', 'temp'); 
if (!fs.existsSync(TEMP_DIR)) {
    fs.mkdirSync(TEMP_DIR, { recursive: true });
}

// 1. Baixa a m√≠dia do WhatsApp para Buffer (MEM√ìRIA)
async function mediaToBuffer(messageContent) {
    try {
        const type = getContentType(messageContent);
        const stream = await downloadContentFromMessage(messageContent[type], type.replace('Message', '')); 
        let buffer = Buffer.from([]);
        for await (const chunk of stream) {
            buffer = Buffer.concat([buffer, chunk]);
        }
        return buffer;
    } catch (e) {
        logger.error(`‚ùå Erro ao baixar stream de m√≠dia: ${e.message}`);
        throw new Error("Falha no download da m√≠dia.");
    }
}

// 2. Transcreve √Åudio (Usa Whisper API - Custo Adicional)
async function transcribeAudio(audioBuffer, mimeType) {
    const tempFileName = `audio_${Date.now()}.${mimeType.split('/')[1] || 'mp3'}`;
    const tempFilePath = path.join(TEMP_DIR, tempFileName);

    try {
        fs.writeFileSync(tempFilePath, audioBuffer); 
        const transcription = await openai.audio.transcriptions.create({
            model: 'whisper-1', 
            file: fs.createReadStream(tempFilePath),
            response_format: 'text', // üö® AJUSTE: Garante o formato de retorno
        });
        return transcription.text;
    } catch (e) {
        logger.error(`‚ùå ERRO WHISPER API: ${e.message}`);
        return '[ERRO DE TRANSCRI√á√ÉO]'; 
    } finally {
        if (fs.existsSync(tempFilePath)) {
            fs.unlinkSync(tempFilePath); // CR√çTICO: Limpa o volume do Railway
        }
    }
}

// 3. Fun√ß√£o Principal para Extrair o Conte√∫do para o GPT-5-nano
async function extractDataForAI(incomingMessage) {
    const type = getContentType(incomingMessage.message);
    const messageContent = incomingMessage.message[type];
    const result = { type: 'text', payload: '' }; 

    switch (type) {
        case 'conversation':
            result.payload = messageContent.conversation || '';
            break;
        case 'extendedTextMessage':
            result.payload = messageContent.text || '';
            break;

        case 'documentMessage':
            if (messageContent.mimetype && messageContent.mimetype.includes('pdf')) {
                try {
                    const buffer = await mediaToBuffer(incomingMessage.message);
                    const data = await pdf(buffer);
                    const textSnippet = data.text.substring(0, 4000); 
                    result.payload = `[AN√ÅLISE DE PDF] Conte√∫do: ${textSnippet}. Instru√ß√£o: Resuma o PDF em 3 frases de forma concisa.`;
                } catch (error) {
                    logger.error(`‚ùå Erro ao processar PDF: ${error.message}`);
                    result.payload = `[Erro ao processar PDF]. Instru√ß√£o: Avise o usu√°rio que houve um erro ao processar o documento.`;
                }
            } else {
                result.payload = `[Documento recebido]. Instru√ß√£o: Avise o usu√°rio que voc√™ s√≥ processa texto e PDFs.`;
            }
            break;

        case 'audioMessage':
            try {
                const buffer = await mediaToBuffer(incomingMessage.message);
                const mimeType = messageContent.mimetype || 'audio/mpeg';
                const transcriptionText = await transcribeAudio(buffer, mimeType);
                
                if (transcriptionText === '[ERRO DE TRANSCRI√á√ÉO]') {
                    // üö® AJUSTE: Mensagem de erro humanizada
                    result.payload = "Desculpe, n√£o consegui transcrever o √°udio. Por favor, envie a mensagem como texto.";
                } else {
                    result.payload = `[√ÅUDIO TRANSCREVIDO: ${transcriptionText}]. Instru√ß√£o: Responda ao √°udio de forma concisa.`;
                }
            } catch (error) {
                logger.error(`‚ùå Erro ao processar √°udio: ${error.message}`);
                result.payload = "Desculpe, houve um erro inesperado ao processar seu √°udio. Tente novamente.";
            }
            break;

        case 'imageMessage':
        case 'videoMessage':
            let captionText = messageContent.caption || '';
            let advisoryText = `[M√çDIA VISUAL RECEBIDA: ${type.replace('Message', '').toUpperCase()}]. `;
            
            if (captionText) {
                advisoryText += `O usu√°rio escreveu: "${captionText}". Analise apenas este texto, pois o modelo n√£o consegue ver a imagem/v√≠deo.`;
            } else {
                advisoryText += `O modelo de IA n√£o possui Vis√£o. Solicite ao usu√°rio que descreva o arquivo.`;
            }
            result.payload = advisoryText;
            break;

        default:
            result.payload = `Mensagem do tipo ${type} recebida. Instru√ß√£o: Avise o usu√°rio que este tipo de mensagem n√£o √© processado.`;
            break;
    }
    
    return result; 
}

module.exports = { extractDataForAI };

